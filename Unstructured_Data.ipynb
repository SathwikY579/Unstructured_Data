{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfrcPdZR31bi",
        "outputId": "8ccf6286-2877-4ff3-bbb5-b474ab804016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Extracting"
      ],
      "metadata": {
        "id": "5EkjEuqI7ir2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the articles, given in the input.xlsx file, extract the article text and save the extracted article in a text file with URL_ID as its file name.\n"
      ],
      "metadata": {
        "id": "44lT7Gye72Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/UD/UD_Input.xlsx')\n",
        "\n",
        "def extract_and_save(url, filename):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Check for errors\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        title = soup.title.string.strip() if soup.title else \"No Title\"\n",
        "        article_text = '\\n'.join([p.text.strip() for p in soup.find_all('p')])\n",
        "        with open(filename, 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"{title}\\n\\n{article_text}\")\n",
        "        print(f\"Article extracted and saved successfully: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting data from {url}: {e}\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "    filename = f\"{url_id}.txt\"\n",
        "    extract_and_save(url, filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMDPSGfo3-As",
        "outputId": "c01d0bfa-6213-440c-be82-0f4928456ed3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article extracted and saved successfully: LINK_01.txt\n",
            "Article extracted and saved successfully: LINK_02.txt\n",
            "Article extracted and saved successfully: LINK_03.txt\n",
            "Article extracted and saved successfully: LINK_04.txt\n",
            "Article extracted and saved successfully: LINK_05.txt\n",
            "Article extracted and saved successfully: LINK_06.txt\n",
            "Article extracted and saved successfully: LINK_07.txt\n",
            "Article extracted and saved successfully: LINK_08.txt\n",
            "Article extracted and saved successfully: LINK_09.txt\n",
            "Article extracted and saved successfully: LINK_10.txt\n",
            "Article extracted and saved successfully: LINK_11.txt\n",
            "Article extracted and saved successfully: LINK_12.txt\n",
            "Article extracted and saved successfully: LINK_13.txt\n",
            "Article extracted and saved successfully: LINK_14.txt\n",
            "Article extracted and saved successfully: LINK_15.txt\n",
            "Article extracted and saved successfully: LINK_16.txt\n",
            "Article extracted and saved successfully: LINK_17.txt\n",
            "Article extracted and saved successfully: LINK_18.txt\n",
            "Article extracted and saved successfully: LINK_19.txt\n",
            "Article extracted and saved successfully: LINK_20.txt\n",
            "Article extracted and saved successfully: LINK_21.txt\n",
            "Article extracted and saved successfully: LINK_22.txt\n",
            "Article extracted and saved successfully: LINK_23.txt\n",
            "Article extracted and saved successfully: LINK_24.txt\n",
            "Article extracted and saved successfully: LINK_25.txt\n",
            "Article extracted and saved successfully: LINK_26.txt\n",
            "Article extracted and saved successfully: LINK_27.txt\n",
            "Article extracted and saved successfully: LINK_28.txt\n",
            "Article extracted and saved successfully: LINK_29.txt\n",
            "Article extracted and saved successfully: LINK_30.txt\n",
            "Article extracted and saved successfully: LINK_31.txt\n",
            "Article extracted and saved successfully: LINK_32.txt\n",
            "Article extracted and saved successfully: LINK_33.txt\n",
            "Article extracted and saved successfully: LINK_34.txt\n",
            "Article extracted and saved successfully: LINK_35.txt\n",
            "Article extracted and saved successfully: LINK_36.txt\n",
            "Article extracted and saved successfully: LINK_37.txt\n",
            "Article extracted and saved successfully: LINK_38.txt\n",
            "Article extracted and saved successfully: LINK_39.txt\n",
            "Article extracted and saved successfully: LINK_40.txt\n",
            "Article extracted and saved successfully: LINK_41.txt\n",
            "Article extracted and saved successfully: LINK_42.txt\n",
            "Article extracted and saved successfully: LINK_43.txt\n",
            "Article extracted and saved successfully: LINK_44.txt\n",
            "Article extracted and saved successfully: LINK_45.txt\n",
            "Article extracted and saved successfully: LINK_46.txt\n",
            "Article extracted and saved successfully: LINK_47.txt\n",
            "Article extracted and saved successfully: LINK_48.txt\n",
            "Article extracted and saved successfully: LINK_49.txt\n",
            "Article extracted and saved successfully: LINK_50.txt\n",
            "Article extracted and saved successfully: LINK_51.txt\n",
            "Article extracted and saved successfully: LINK_52.txt\n",
            "Article extracted and saved successfully: LINK_53.txt\n",
            "Article extracted and saved successfully: LINK_54.txt\n",
            "Article extracted and saved successfully: LINK_55.txt\n",
            "Article extracted and saved successfully: LINK_56.txt\n",
            "Article extracted and saved successfully: LINK_57.txt\n",
            "Article extracted and saved successfully: LINK_58.txt\n",
            "Article extracted and saved successfully: LINK_59.txt\n",
            "Article extracted and saved successfully: LINK_60.txt\n",
            "Article extracted and saved successfully: LINK_61.txt\n",
            "Article extracted and saved successfully: LINK_62.txt\n",
            "Article extracted and saved successfully: LINK_63.txt\n",
            "Article extracted and saved successfully: LINK_64.txt\n",
            "Article extracted and saved successfully: LINK_65.txt\n",
            "Article extracted and saved successfully: LINK_66.txt\n",
            "Article extracted and saved successfully: LINK_67.txt\n",
            "Article extracted and saved successfully: LINK_68.txt\n",
            "Article extracted and saved successfully: LINK_69.txt\n",
            "Article extracted and saved successfully: LINK_70.txt\n",
            "Article extracted and saved successfully: LINK_71.txt\n",
            "Article extracted and saved successfully: LINK_72.txt\n",
            "Article extracted and saved successfully: LINK_73.txt\n",
            "Article extracted and saved successfully: LINK_74.txt\n",
            "Article extracted and saved successfully: LINK_75.txt\n",
            "Article extracted and saved successfully: LINK_76.txt\n",
            "Article extracted and saved successfully: LINK_77.txt\n",
            "Article extracted and saved successfully: LINK_78.txt\n",
            "Article extracted and saved successfully: LINK_79.txt\n",
            "Article extracted and saved successfully: LINK_80.txt\n",
            "Article extracted and saved successfully: LINK_81.txt\n",
            "Article extracted and saved successfully: LINK_82.txt\n",
            "Article extracted and saved successfully: LINK_83.txt\n",
            "Article extracted and saved successfully: LINK_84.txt\n",
            "Article extracted and saved successfully: LINK_85.txt\n",
            "Article extracted and saved successfully: LINK_86.txt\n",
            "Article extracted and saved successfully: LINK_87.txt\n",
            "Article extracted and saved successfully: LINK_88.txt\n",
            "Article extracted and saved successfully: LINK_89.txt\n",
            "Article extracted and saved successfully: LINK_90.txt\n",
            "Article extracted and saved successfully: LINK_91.txt\n",
            "Article extracted and saved successfully: LINK_92.txt\n",
            "Article extracted and saved successfully: LINK_93.txt\n",
            "Article extracted and saved successfully: LINK_94.txt\n",
            "Article extracted and saved successfully: LINK_95.txt\n",
            "Article extracted and saved successfully: LINK_96.txt\n",
            "Article extracted and saved successfully: LINK_97.txt\n",
            "Article extracted and saved successfully: LINK_98.txt\n",
            "Article extracted and saved successfully: LINK_99.txt\n",
            "Article extracted and saved successfully: LINK_100.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis"
      ],
      "metadata": {
        "id": "cJnsHcpu8AX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the extracted texts from the article, perform textual analysis and compute variables, given in the output structure excel file."
      ],
      "metadata": {
        "id": "tlBFWXfq8Er6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "output_df = pd.read_excel('/content/drive/MyDrive/UD/UD_Output.xlsx')\n",
        "\n",
        "def analyze_text(text):\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    word_count = len(doc)\n",
        "    unique_words = len(set([token.text.lower() for token in doc if token.is_alpha and token.text.lower() not in STOP_WORDS]))\n",
        "    sentence_count = len(list(doc.sents))\n",
        "    return word_count, unique_words, sentence_count\n",
        "\n",
        "for index, row in output_df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    filename = f\"{url_id}.txt\"\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            article_text = file.read()\n",
        "        word_count, unique_words, sentence_count = analyze_text(article_text)\n",
        "        output_df.at[index, 'Word_Count'] = word_count\n",
        "        output_df.at[index, 'Unique_Words'] = unique_words\n",
        "        output_df.at[index, 'Sentence_Count'] = sentence_count\n",
        "\n",
        "        print(f\"Textual analysis completed for {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing text from {filename}: {e}\")\n",
        "\n",
        "output_df.to_excel('/content/drive/MyDrive/UD/UD_Output.xlsx', index=False)\n",
        "print(\"Analysis results saved to output_results.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR-FqeNB4V9u",
        "outputId": "7fa5360c-4032-4c0c-852e-8d438012a616"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textual analysis completed for LINK_01.txt\n",
            "Textual analysis completed for LINK_02.txt\n",
            "Textual analysis completed for LINK_03.txt\n",
            "Textual analysis completed for LINK_04.txt\n",
            "Textual analysis completed for LINK_05.txt\n",
            "Textual analysis completed for LINK_06.txt\n",
            "Textual analysis completed for LINK_07.txt\n",
            "Textual analysis completed for LINK_08.txt\n",
            "Textual analysis completed for LINK_09.txt\n",
            "Textual analysis completed for LINK_10.txt\n",
            "Textual analysis completed for LINK_11.txt\n",
            "Textual analysis completed for LINK_12.txt\n",
            "Textual analysis completed for LINK_13.txt\n",
            "Textual analysis completed for LINK_14.txt\n",
            "Textual analysis completed for LINK_15.txt\n",
            "Textual analysis completed for LINK_16.txt\n",
            "Textual analysis completed for LINK_17.txt\n",
            "Textual analysis completed for LINK_18.txt\n",
            "Textual analysis completed for LINK_19.txt\n",
            "Textual analysis completed for LINK_20.txt\n",
            "Textual analysis completed for LINK_21.txt\n",
            "Textual analysis completed for LINK_22.txt\n",
            "Textual analysis completed for LINK_23.txt\n",
            "Textual analysis completed for LINK_24.txt\n",
            "Textual analysis completed for LINK_25.txt\n",
            "Textual analysis completed for LINK_26.txt\n",
            "Textual analysis completed for LINK_27.txt\n",
            "Textual analysis completed for LINK_28.txt\n",
            "Textual analysis completed for LINK_29.txt\n",
            "Textual analysis completed for LINK_30.txt\n",
            "Textual analysis completed for LINK_31.txt\n",
            "Textual analysis completed for LINK_32.txt\n",
            "Textual analysis completed for LINK_33.txt\n",
            "Textual analysis completed for LINK_34.txt\n",
            "Textual analysis completed for LINK_35.txt\n",
            "Textual analysis completed for LINK_36.txt\n",
            "Textual analysis completed for LINK_37.txt\n",
            "Textual analysis completed for LINK_38.txt\n",
            "Textual analysis completed for LINK_39.txt\n",
            "Textual analysis completed for LINK_40.txt\n",
            "Textual analysis completed for LINK_41.txt\n",
            "Textual analysis completed for LINK_42.txt\n",
            "Textual analysis completed for LINK_43.txt\n",
            "Textual analysis completed for LINK_44.txt\n",
            "Textual analysis completed for LINK_45.txt\n",
            "Textual analysis completed for LINK_46.txt\n",
            "Textual analysis completed for LINK_47.txt\n",
            "Textual analysis completed for LINK_48.txt\n",
            "Textual analysis completed for LINK_49.txt\n",
            "Textual analysis completed for LINK_50.txt\n",
            "Textual analysis completed for LINK_51.txt\n",
            "Textual analysis completed for LINK_52.txt\n",
            "Textual analysis completed for LINK_53.txt\n",
            "Textual analysis completed for LINK_54.txt\n",
            "Textual analysis completed for LINK_55.txt\n",
            "Textual analysis completed for LINK_56.txt\n",
            "Textual analysis completed for LINK_57.txt\n",
            "Textual analysis completed for LINK_58.txt\n",
            "Textual analysis completed for LINK_59.txt\n",
            "Textual analysis completed for LINK_60.txt\n",
            "Textual analysis completed for LINK_61.txt\n",
            "Textual analysis completed for LINK_62.txt\n",
            "Textual analysis completed for LINK_63.txt\n",
            "Textual analysis completed for LINK_64.txt\n",
            "Textual analysis completed for LINK_65.txt\n",
            "Textual analysis completed for LINK_66.txt\n",
            "Textual analysis completed for LINK_67.txt\n",
            "Textual analysis completed for LINK_68.txt\n",
            "Textual analysis completed for LINK_69.txt\n",
            "Textual analysis completed for LINK_70.txt\n",
            "Textual analysis completed for LINK_71.txt\n",
            "Textual analysis completed for LINK_72.txt\n",
            "Textual analysis completed for LINK_73.txt\n",
            "Textual analysis completed for LINK_74.txt\n",
            "Textual analysis completed for LINK_75.txt\n",
            "Textual analysis completed for LINK_76.txt\n",
            "Textual analysis completed for LINK_77.txt\n",
            "Textual analysis completed for LINK_78.txt\n",
            "Textual analysis completed for LINK_79.txt\n",
            "Textual analysis completed for LINK_80.txt\n",
            "Textual analysis completed for LINK_81.txt\n",
            "Textual analysis completed for LINK_82.txt\n",
            "Textual analysis completed for LINK_83.txt\n",
            "Textual analysis completed for LINK_84.txt\n",
            "Textual analysis completed for LINK_85.txt\n",
            "Textual analysis completed for LINK_86.txt\n",
            "Textual analysis completed for LINK_87.txt\n",
            "Textual analysis completed for LINK_88.txt\n",
            "Textual analysis completed for LINK_89.txt\n",
            "Textual analysis completed for LINK_90.txt\n",
            "Textual analysis completed for LINK_91.txt\n",
            "Textual analysis completed for LINK_92.txt\n",
            "Textual analysis completed for LINK_93.txt\n",
            "Textual analysis completed for LINK_94.txt\n",
            "Textual analysis completed for LINK_95.txt\n",
            "Textual analysis completed for LINK_96.txt\n",
            "Textual analysis completed for LINK_97.txt\n",
            "Textual analysis completed for LINK_98.txt\n",
            "Textual analysis completed for LINK_99.txt\n",
            "Textual analysis completed for LINK_100.txt\n",
            "Analysis results saved to output_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "qbEUozr64V-3",
        "outputId": "865d838d-426a-4254-e59c-160db0c79e97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/UD_Input1.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6ce97d7e4c1a>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/UD_Input1.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/UD_Input1.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syZCAVoXSCsl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}